<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Charlie Chen, Maxwell Lo</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href=https://cal-cs184-student.github.io/takethedigitalprivacydecal-webpage/proj3-1/index.html">https://cal-cs184-student.github.io/takethedigitalprivacydecal-webpage/proj3-1/index.html</a></h2>

<br><br>

<!--
<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>
<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> 
<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>
<ul>
<li>Your main report page should be called index.html.</li>
<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>
<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
<li>And again, test your website on the instructional machines early!</li>
</ul>


<p>Here is an example of how to include a simple formula:</p>
<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>

<div>
-->

<h2 align="middle">Overview</h2>
<p>
    In this project, we implemented a path tracing model that allowed us to render complicated images, complete with 
    light sources and global illumination. This allows us to generate realistic images with shadows and varying 
    levels of brightness. By using a geometric representation of an object in the form of a mesh, we can cast rays 
    through each pixel in the image and take their resulting emissions to get the color associated with each pixel. 
    By having the rays "bounce" around the image (which is actually just casting a new ray from the point where it 
    intersected the object), we can collect indirect lighting samples and use that to generate a more complete image. 
    Overall, the results of this project were very cool to see and it was fun to watch as the images went from nothing 
    to a bunch of sporadic colors to photorealistic images with shadows. However, it also became clear that having high 
    quality images takes a very long time to simulate/compute the resultant lighting. 
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    YOUR RESPONSE GOES HERE
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    YOUR RESPONSE GOES HERE
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example3.dae</figcaption>
      </td>
      <td>
        <img src="images/your_file.png" align="middle" width="400px"/>
        <figcaption>example4.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    To construct a BVH, we recurisvely pick a splitting point and divide into further BVH nodes until the number of primitive objects is less than or equal to max_lef_size.
	To pick a splitting point, we first need to pick an axis to split on. We do this by taking the span of the bounding box in the x, y, and z, dimensions and picking the axis that the bounding box is largest in. Then we compute the point along that axis that we will split on by taking the geometric center (centroid) of the bounding box. There are likely more complex heuristics, but this one is simple are results is an efficient enough bvh for our needs.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/2-1_cbdragon.png" align="middle" width="400px"/>
        <figcaption>cbdragon.dae</figcaption>
      </td>
      <td>
        <img src="images/2-1_cblucy.png" align="middle" width="400px"/>
        <figcaption>cblucy.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    We compared rendering times for cow.dae and for maxplanck.dae. Cow.dae originally took 17.6 seconds to render, requiring an average of 949.0 intersection tests per ray. With BVH acceleration, the cow took 0.13 seconds to render, and required an average of 0.83 intersection tests per ray. We noticed that BVH acceleration caused the BVH building process to take slighly longer, with 0.0001 seconds for the non-BVH version and 0.0102 seconds for the BVH version. This slighly longer construction time is however greatly faster than the difference in render times. Rendering maxplanck.dae told a similar story, with the non-BVH version taking 157.54 seconds to render and the BVH version taking 0.2402 seconds, as seen in the screenshots below. This makes sense as without BVH we had to check each ray against all primitives in the scene, but we now only check each ray against primitivies in leaf BVHNodes that the ray intersects, as well as the relevant non-leaf BVHNodes required to traverse the tree.
</p>
<div align="middle">
	<table style="width:100%">
	  <tr align="center">
		<td>
		  <img src="images/2-1_rendertime_pre_bvh_maxplanck.png" align="middle" width="400px"/>
		  <figcaption>Render time for maxplanck.dae without BVH.</figcaption>
		</td>
		<td>
		  <img src="images/2-1_rendertime_post_bvh_maxplanck.png" align="middle" width="400px"/>
		  <figcaption>Render time for maxplanck.dae with BVH.</figcaption>
		</td>
	  </tr>
	</table>
  </div>
  <br>
<br>



<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    To calculate direct lighting, we need to account for two things: rays of light that directly hit the camera from the light source in zero-bounce illumination, and rays of light that hit an object and then hit the camera off the object in one-bounce illumination. The ratio of light that bounces off an object is given by the object's BSDF. The irradiance at a given point is the integral over all the light arriving at that point, and we can use Monte-Carlo integration to efficiently estimate this. We have two implementations of direct lighting, hemisphere sampling and importance sampling. Hemisphere sampling takes samples across the hemisphere with equal probability, in practice, this looks like taking m sample rays from the intersection point, determine whether the sample rays intersect a light source, sum the sampled light, and divide by the number of samples to get an estimate for the irrdiance. Importance sampling has greater probability of sampling from a light source, in practice, this looks very similar to hemisphere sampling except the sampled direction is sampled from the light. Importance sampling also allows us to render with point light sources in our scenes.
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/q3-sphere-hemisphere.png" align="middle" width="400px"/>
        <figcaption>sphere.dae hemisphere sampled</figcaption>
      </td>
      <td>
        <img src="images/q3-walle-importance.png" align="middle" width="400px"/>
        <figcaption>walle.dae importance sampled</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/q3-bunny-hemisphere.png" align="middle" width="400px"/>
        <figcaption>bunny.dae hemisphere sampled</figcaption>
      </td>
      <td>
        <img src="images/q3-dragon-importance.png" align="middle" width="400px"/>
        <figcaption>dragon.dae importance sampled</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/q3-bunny-1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/q3-bunny-4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q3-bunny-16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/q3-bunny-64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    Rendering with fewer light rays per pixel will result in more overall noise in the entire image, but the increased noise much higher around soft shadows with direct lighting becuase the path from that pixel to the area light source is only partially blocked by an object. As such, the phenomenon of soft shadows is much better modeled with global illumination that takes into consideration light bouncing off non light source objects. 
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    With the same number of samples, lighting sampling looks less noisy than hemisphere sampling because it is less likely for all the samples to miss the light source, since the pdf we use will favor the lights. Our implementation of lighting sampling does take longer than hemisphere sampling as we take n_samples for every area light source per position and 1 sample for every point light source per position, instead of just n-samples total per position, However if we normalized the n_samples to be the same in both implementations, the compute time to noise ratio will still be better for lighting sampling.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    To implement indirect lighting, we expand on our initial direct lighting implementation by recursively adding 
    the illuminance caused by the resulting ray's bounces. Because a ray could in theory bounce infinitely, adding 
    progressively smaller amounts of illuminance each time, we set a maximum ray depth which limits the number of 
    bounces a ray can perform (with having a max ray depth of 0 being equivalent to having only direct lighting). 
    Additionally, we implement a russian roulette system that immediately terminates a ray with a probability of 0.3. 
    While this does cut down on the effect of rays that would usually bounce a very large number of times, the 
    additional effect caused by those rays is expected to be very low anyways, and so it does not affect the result 
    of the image very much. 
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/q4-bunny-global.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae with global illumination</figcaption>
      </td>
      <td>
        <img src="images/q4-dragon-global.png" align="middle" width="400px"/>
        <figcaption>dragon.dae with global illumination</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/q4-bunny-direct.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/q4-bunny-indirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    With only direct illumination, the light source at the top of the box is the only light source, and so the bottom 
    of the bunny ends up very dark as there is no external lighting. With indirect illumination, even areas such as the 
    underside of the bunny are slightly lit, and the resulting image is much softer.
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/q4-bunny-0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/q4-bunny-max_depth_1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q4-bunny-max_depth_2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/q4-bunny-max_depth_3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q4-bunny-max_depth_100.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    We see that the bunny with max_ray_depth of 0 is equivalent to the bunny with only direct illumination as 
    shown above. When increasing the depth to 1, we immediately get the effects of having indirect lighting, 
    which causes the bunny to be lit even on its underside. However, further increases of max_depth do not have 
    very pronounced effect, as they are only increasing fractional amounts of illuminance with each additional 
    bounce. With the depth 100 bunny, the light has converged long before 100 bounces (or been terminated by 
    russian roulette), and so it looks almost identical to the depth 3 bunny. 
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/q4-spheres-1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/q4-spheres-2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q4-spheres-4.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/q4-spheres-8.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q4-spheres-16.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/q4-spheres-64.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q4-spheres-1024.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Here we compare various images of spheres constructed with various sample-per-pixel rates, each with 
    4 light rays and a max bounce depth of 5. We see that increasing the number of camera rays per pixel 
    results in much better quality, but it also comes at a high computational cost. 
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling essentially consists of ending certain samples early when their illumination level converges 
    to a specified tolerance level (which we define to be 1.96 * standard deviation/sqrt(number of samples)), so that 
    we do not have to spend extra computational power on sampling lights that seem to be unchanging. Initially, our 
    raytrace_pixel function ran some number of samples n for each pixel, but with adaptive sampling, we keep a running 
    sum of illuminance for the generated samples, and if it reaches the convergence point we end the sampling early. In 
    the images below, we see that the red areas represent areas where there were many camera samples (the illuminance 
    did not converge quickly) and the dark blue areas represent areas where the samples converged quickly. 
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/q5-bunny.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/q5-bunny_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/q5-CBspheres_lambertian.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="images/q5-CBspheres_lambertian_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBspheres_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>

