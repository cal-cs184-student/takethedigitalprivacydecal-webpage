<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">CS184-takethedigitalprivacydegal</h2>
<h2 align="middle">Maxwell Lo, Charlie Chen</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<!-- <p>Give a high-level overview of what you implemented in this project. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the project.</p> -->
<p1>
I think it's really cool that we built a rasterizer. It is very interesting to think about how although everything on a computer technically exists digitally as 1s and 0s, the graph functions that they represent are analog enough to the degree that we need to sample them.
</p1>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
<p1>We rasterize by taking samples at the middle of each pixel. Since a triangle can be represented by the intersection of 3 half-planes, we test each sample point with 3 line tests to determine if that pixel falls on or on the same side of all 3 lines that create the triangle, in which case we fill the pixel.
<br/>
Our algorithm is no worse than one that checks each sample within the bounding box of the triangle because it is exacty one that checks each sample within the bounding box of the triangle, as that is exactly what we do.</p1>

<div align="middle">
	<img src="images/1-basictest4.png" align="middle" width="600px"/>
	<figcaption align="middle">Floaties caused by aliasing.</figcaption>
</div>

<p1>The above image shows basic rasterization on 4 triangles. Aliasing is evident, especially when zoomed in on the tip of the purple triangle. This is because the tip of that triangle has a width less than 1 pixel wide, and since we only sample in the middle of the pixel at intervals of 1 pixel, it is possible for part of the triangle to exist between our two sample points and not get captured, but a future part that happens to lie on our sample point, resulting gin these floaties.</p1>

<!-- 
<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/image1.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image2.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/image3.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image4.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
  </table>
</div> 
-->


<h3 align="middle">Part 2: Antialiasing triangles</h3>
<p1>To perform antialiasing, we supersampled the images.
  Originally, the rasterization process involved creating a sample buffer of each pixel which was then
  added to the frame buffer. Instead, we created a set of n x n pixels (where n is sqrt(sample_rate))
  for each original pixel and used these to generate a much larger image, with dimensions
  (width * height * sample_rate). After the large image was generated, we then collected every n x n square
  and averaged the colors together to get a single amortized colored pixel, which was put into the frame buffer.
  This gave us a frame buffer with the same number of pixels as the original image but now with certain pixels
  (especially those near the edges) having less extreme colors, reducing aliasing.

  <br>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/basic_4_sample_1.png" align="middle" width="300px">
          <figcaption align="middle">Triangle with sample rate of 1</figcaption>
        </td>
        <td>
          <img src="images/basic_4_sample_4.png" align="middle" width="300px">
          <figcaption align="middle">Triangles with sample rate of 4.</figcaption>
        </td>
        <td>
          <img src="images/basic_4_sample_16.png" align="middle" width="300px">
          <figcaption align="middle">Triangles with sample rate of 16.</figcaption>
        </td>
      </tr>
    </table>
  </div>
  <br>
  We see that when we sample with a sampling rate of 1, the image only has either dark red or white pixels,
  as there is nothing to average into. This results in an image with more jagged edges.
  <br>
  When we sample with a sampling rate of 4, we begin to have some non-purely dark red or white pixels,
  instead having some lighter red pixels that round out the shape. This reduces aliasing.
  <br>
  When we sample at a rate of 16, there is even less aliasing, and even the zoomed in version of the image appears
  much more smooth than the other two images.
</p1>


<h3 align="middle">Part 3: Transforms</h3>
<p1>Implementing 2D transformations involved creating the 3x3 transformation matricies using homogenous coordinates.

<div align="middle">
	<img src="images/3-my-robot.png" align="middle" width="600px">
	<figcaption align="middle">Baller robot.</figcaption>
</div>

</br>
I increased the scale of the robot's head to be more proportional to their body, rotated the robot's legs to be in a more atheletic stance, scaled their feet to be cool green basketball shoes, and rotated their arm to be able to better grasp the basketball. I noticed that due to the heirarchical representation of the robot, rotating the arm resulted in both the upper and lower arm rotating together.
</p1>


<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>
<p1>
Barycentric coordinates are a way of representing coordinates within a triangle. Given the 3 vertecies that make up a triangle, each point within the triangle can be represented by the sum of some vector multiplited by each of those vertecies. This is very useful for interpolation, as an example, the triangle below has one red, one green, and one blue vertex. At the red vertex it is 100% red and 0% blue and green, resulting in only red. In the middle of the triangle it is 50% red, 50% blue, and 50% green, resulting in a gray color. The midpoint of the left edge of the triangle is 50% red, 50% blue, and 0% green, resulting in a purple color.
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/4-3colortriangle.png" align="middle" width="400px">
        <figcaption align="middle">Barycentric coordinates example.</figcaption>
      </td>
      <td>
        <img src="images/4-basictest7.png" align="middle" width="400px">
        <figcaption align="middle">Basic test 7.</figcaption>
      </td>
    </tr>
  </table>
</div>
</p1>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
<p1>
  Pixel sampling for texture mapping is quite similar to sampling for triangle rasterization. For each pixel of the object, we sample a pixel of the texture and apply it to the object. The two ways of sampling are nearest and bilinear. Nearest takes the floor of the sample point coordinates and applies the texture pixel at those coordinates. Bilinear takes the 4 nearest texture pixels from the sample point and averages them based on distance from the sample point, with the closest one having the highest weight.

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/image4.png" align="middle" width="400px"/>
          <figcaption align="middle">Nearest sampling at 1 sample per pixel.</figcaption>
        </td>
        <td>
          <img src="images/image4.png" align="middle" width="400px"/>
          <figcaption align="middle">Nearest sampling at 16 samples per pixel.</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/image4.png" align="middle" width="400px"/>
          <figcaption align="middle">Bilinear sampling at 1 sample per pixel.</figcaption>
        </td>
        <td>
          <img src="images/image4.png" align="middle" width="400px"/>
          <figcaption align="middle">Bilinear sampling at 16 samples per pixel.</figcaption>
        </td>
      </tr>
    </table>
  </div>
  </br>
  Pixel sampling faces the same aliasing issues as seen previously. When the texture resolution and object resolution are the same, nearest sampling works best, as there will be a 1 to 1 mapping between each pixel on the object and each pixel on the texture. Bilinear might not work as well in this case depending on the sampling point chosen, as if we choose the corner  of a pixel it will average the 4 nearest, resulting is a less clear texture when compared to the nearest sampling, while requiring 4 times as many samples.
  <br/>
  When the texture resolution and object resolution are different, bilinear will work better than nearest. If the texture resolution is greater than the ojbect resolution, we get minification, nearest sampling will skip multiple texture pixels between each object pixel, resulting is a really 'jumpy' texture. If the texture resolution is less than the object resolution, we get magnification, nearest sampling will then use the same texture pixel for multiple object pixels, resulting in very jagged lines. In both these cases, bilinear sampling will create a smoother outcome.
</p1>

<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>



<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
